{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  0.1.80\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import azureml\n",
    "import logging\n",
    "from azureml.core.model import Model\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core import Workspace, Run, Datastore, Experiment\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.train.hyperdrive import *\n",
    "from azureml.train.dnn import TensorFlow\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\projects\\SimpleMNIST\\aml_config\\config.json\n"
     ]
    }
   ],
   "source": [
    "# use this code to set up config file\n",
    "#subscription_id ='<SUB_ID>'\n",
    "#resource_group ='<RESOURCE_GROUP>'\n",
    "#workspace_name = '<WORKSPACE>'\n",
    "\n",
    "#try:\n",
    "#   ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "#   ws.write_config()\n",
    "#   print('Workspace configuration succeeded. You are all set!')\n",
    "#except:\n",
    "#   print('Workspace not found. TOO MANY ISSUES!!!')\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n"
     ]
    }
   ],
   "source": [
    "cluster = 'sauron'\n",
    "try:\n",
    "    compute = ComputeTarget(workspace=ws, name=cluster)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC6', min_nodes=1, max_nodes=6)\n",
    "    compute = ComputeTarget.create(ws, cluster, compute_config)\n",
    "    compute.wait_for_completion(show_output=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run experiment\n",
    "mnist = Experiment(ws, 'simplemnist')\n",
    "estimator = TensorFlow(source_directory='.',\n",
    "                       compute_target=compute,\n",
    "                       entry_script='train.py',\n",
    "                       use_gpu=True)\n",
    "\n",
    "run = mnist.submit(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manage Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Target already exists. Skipping upload for mnist\\mnist.npz\n"
     ]
    }
   ],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "mnist_data = ds.upload(src_dir = 'data', target_path = 'mnist', show_progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the same was as above\n",
    "script_params={\n",
    "    '--data': mnist_data.as_mount(),\n",
    "}\n",
    "\n",
    "# Create and run experiment\n",
    "mnist = Experiment(ws, 'simplemnist')\n",
    "estimator = TensorFlow(source_directory='.',\n",
    "                       compute_target=compute,\n",
    "                       entry_script='train.py',\n",
    "                       script_params=script_params,\n",
    "                       use_gpu=True)\n",
    "\n",
    "run = mnist.submit(estimator)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above but increase the max_steps and remove the parameters\n",
    "script_params={\n",
    "    '--data': mnist_data,\n",
    "    '--epochs': 100\n",
    "}\n",
    "\n",
    "mnist = Experiment(ws, 'simplemnist')\n",
    "estimator = TensorFlow(source_directory='.',\n",
    "                       compute_target=compute,\n",
    "                       entry_script='train.py',\n",
    "                       script_params=script_params,\n",
    "                       use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c77d6fabca6446585a8b4c377c14dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'NOTSEâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ps = RandomParameterSampling(\n",
    "    {\n",
    "        '--lr': loguniform(-15, -3),\n",
    "        '--batch': choice(16, 32, 64, 128)\n",
    "    }\n",
    ")\n",
    "\n",
    "early_termination_policy = BanditPolicy(slack_factor = 0.15, evaluation_interval=2)\n",
    "\n",
    "hyperdrive_run_config = HyperDriveRunConfig(estimator = estimator, \n",
    "                                            hyperparameter_sampling = ps, \n",
    "                                            policy = early_termination_policy,\n",
    "                                            primary_metric_name = \"accuracy\",\n",
    "                                            primary_metric_goal = PrimaryMetricGoal.MAXIMIZE,\n",
    "                                            max_total_runs = 20,\n",
    "                                            max_concurrent_runs = 5)\n",
    "\n",
    "hd_run = mnist.submit(hyperdrive_run_config)\n",
    "\n",
    "RunDetails(hd_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hd_run.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"name\": \"AutoML_Demo_Experiment_{0}\".format(time.time()),\n",
    "    \"iteration_timeout_minutes\": 5,\n",
    "    \"iterations\": 20,\n",
    "    \"n_cross_validations\": 5,\n",
    "    \"primary_metric\": 'AUC_weighted',\n",
    "    \"preprocess\": False,\n",
    "    \"max_concurrent_iterations\": 10,\n",
    "    \"verbosity\": logging.INFO\n",
    "}\n",
    "\n",
    "automl_config = AutoMLConfig(task='classification',\n",
    "                             debug_log='automl_errors.log',\n",
    "                             path='.',\n",
    "                             compute_target = compute,\n",
    "                             data_script='./get_data.py',\n",
    "                             **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on remote compute: sauron\n",
      "Parent Run ID: AutoML_b3539306-d3d5-45e8-b131-78f568245759\n",
      "*******************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "*******************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          0:05:02       0.9935    0.9935\n",
      "         1   StandardScalerWrapper LightGBM                 0:09:18       0.9964    0.9964\n",
      "         2   StandardScalerWrapper LogisticRegression       0:12:36       0.9877    0.9964\n",
      "         4   RobustScaler LogisticRegression                0:14:09       0.9893    0.9964\n",
      "         3   StandardScalerWrapper LightGBM                 0:16:15          nan    0.9964\n",
      "         5   RobustScaler ExtremeRandomTrees                0:20:56          nan    0.9964\n",
      "         6   StandardScalerWrapper LightGBM                 0:22:31          nan    0.9964\n",
      "         7   SparseNormalizer LightGBM                      0:24:00          nan    0.9964\n",
      "         8   StandardScalerWrapper LogisticRegression       0:27:07       0.9919    0.9964\n",
      "         9   StandardScalerWrapper LightGBM                 0:27:58       0.9635    0.9964\n",
      "        10   MaxAbsScaler RandomForest                      0:26:57       0.5000    0.9964\n",
      "        11   MaxAbsScaler RandomForest                      0:27:42       0.9689    0.9964\n",
      "        12   StandardScalerWrapper LogisticRegression       0:26:31          nan    0.9964\n",
      "        13   SparseNormalizer LightGBM                      0:24:41          nan    0.9964\n",
      "        14   MinMaxScaler LightGBM                          0:25:53       0.9939    0.9964\n",
      "        17   MaxAbsScaler RandomForest                      0:21:17       0.8725    0.9964\n",
      "        15   StandardScalerWrapper LightGBM                 0:25:30          nan    0.9964\n",
      "        16   MaxAbsScaler LightGBM                          0:24:08          nan    0.9964\n",
      "        19    Ensemble                                      0:20:47       0.9965    0.9965\n"
     ]
    }
   ],
   "source": [
    "experiment=Experiment(ws, 'simplemnist')\n",
    "remote_run = experiment.submit(automl_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5bb66181cc4ba69eb85e7059ba0610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'NOTSET', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(remote_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
